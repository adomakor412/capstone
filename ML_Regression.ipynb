{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from os import path as op\n",
    "import itertools\n",
    "import re\n",
    "import xarray as xr\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy.random as nr\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr.seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputPath = '/scratch/adomakor412/all_npy3'\n",
    "PATH = os.path.expanduser(inputPath)\n",
    "ncPath = os.path.expanduser('/scratch/adomakor412/april_data_2019')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"time\",\n",
    "    \"longitude\",\n",
    "    \"latitude\",\n",
    "    #\"band\",#Necessary?\n",
    "    \"G17_Temp\",\n",
    "    \"G17_mean\",\n",
    "    \"G17_std\",#mean and std outside inner for loop for comp. eff.\n",
    "    \"target_G16_Temp\"\n",
    "]\n",
    "\n",
    "df = pd.DataFrame({},columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longitude(lonMin, lonMax, col, colSize):\n",
    "    lon = (col/colSize)* (lonMax - lonMin)\n",
    "    return lon\n",
    "\n",
    "def latitude(latMin, latMax, row, rowSize):\n",
    "    lat = (row/rowSize)* (latMax - latMin)\n",
    "    return lat\n",
    "\n",
    "def Rad2BT(rad, planck_fk1, planck_fk2, planck_bc1, planck_bc2):\n",
    "    \"\"\"Radiances to Brightness Temprature (using black body equation)\"\"\"\n",
    "    invRad = np.array(rad)**(-1)\n",
    "    arg = (invRad*planck_fk1) + 1.0\n",
    "    T = (- planck_bc1+(planck_fk2 * (np.log(arg)**(-1))) )*(1/planck_bc2) \n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "extent_pc = [-109.59326, -102.40674, 8.94659, -8.94656]\n",
    "\n",
    "dataFrames = []\n",
    "randPool = 401401\n",
    "randSize = 1000#randPool*.1\n",
    "inds=nr.randint(randPool, size=(randSize))\n",
    "inds.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OR_ABI-L1b-RadF-M6C08_G17_s20191030000339_e20191030009405_c20191030009441.nc\n"
     ]
    }
   ],
   "source": [
    "MAE = []\n",
    "MSE = []\n",
    "R2 = []\n",
    "R2_train_test = []\n",
    "\n",
    "trainSamp = [100, 1000, 10000, 100000]\n",
    "for samp in trainSamp:\n",
    "    with open('logML', 'a') as log:\n",
    "\n",
    "        for (bb,dd) in list(itertools.product([8],[5])):#Let's start with one day\n",
    "            DD = str(98+dd).zfill(3)\n",
    "            lookup = f'M6C08_G17_s2019{DD}0000'\n",
    "            ncFiles = [f for f in os.listdir(ncPath) if re.search(lookup,f)]\n",
    "            #ncFiles = mySort(ncFiles)\n",
    "            npFiles = [f for f in os.listdir( PATH ) if re.search(lookup,f)]\n",
    "            #ncFiles = mySort(ncFiles)\n",
    "\n",
    "            for ncf, npf in zip(ncFiles,npFiles):#can refactor to just conversion of selected files\n",
    "                try:\n",
    "                    imageBox = np.load(op.join( PATH,npf))\n",
    "                    myFile = xr.open_dataset(op.join(ncPath,ncf))\n",
    "                    planck_fk1 = float(myFile['planck_fk1'].data)\n",
    "                    planck_fk2 = float(myFile['planck_fk2'].data) \n",
    "                    planck_bc1 = float(myFile['planck_bc1'].data)                       \n",
    "                    planck_bc2 = float(myFile['planck_bc2'].data)\n",
    "\n",
    "                    time = ncf[31:38]\n",
    "                    G17_mean = Rad2BT(imageBox.mean(), planck_fk1, planck_fk2, planck_bc1, planck_bc2)\n",
    "                    G17_std = Rad2BT(imageBox.std(), planck_fk1, planck_fk2, planck_bc1, planck_bc2)\n",
    "\n",
    "                    hh = ncf[34:36]\n",
    "                    mm = ncf[36:38]\n",
    "\n",
    "                    print(ncf)\n",
    "                    print(str(ncf), file=log)\n",
    "                    logger.info(str(ncf))\n",
    "\n",
    "                    G16_npy = np.load( op.join(PATH, npf.replace('G16','G17',1)) )\n",
    "                    G16_ncf = xr.open_dataset(op.join( ncPath, ncf.replace('G16','G17',1) ))\n",
    "                    G16_fk1 = float(G16_ncf['planck_fk1'].data)\n",
    "                    G16_fk2 = float(G16_ncf['planck_fk2'].data) \n",
    "                    G16_bc1 = float(G16_ncf['planck_bc1'].data)                       \n",
    "                    G16_bc2 = float(G16_ncf['planck_bc2'].data)\n",
    "\n",
    "                    target_G16_Temp = Rad2BT(G16_npy, G16_fk1, G16_fk2, G16_bc1, G16_bc2)\n",
    "                    x,y = imageBox.shape[0],imageBox.shape[1]\n",
    "                    randInds = nr.randint(10000, size=(x*y))\n",
    "\n",
    "                    #select \"10,000\" random points out of 401,401\n",
    "                    sample = np.array([combo for combo in itertools.product(range(x),range(y))])\n",
    "                    for i,j in sample:\n",
    "                        lon = longitude( extent_pc[0], extent_pc[1], i, x )\n",
    "                        lat = latitude( extent_pc[2], extent_pc[3], j, y)\n",
    "\n",
    "                        G17_Temp = Rad2BT(imageBox[i,j], planck_fk1, planck_fk2, planck_bc1, planck_bc2)#unfiltered\n",
    "                        target_G16_Temp = Rad2BT( G16_npy[i,j], G16_fk1, G16_fk2, G16_bc1, G16_bc2 )\n",
    "\n",
    "                        row = [time, lon, lat, G17_Temp, G17_mean, G17_std, target_G16_Temp]\n",
    "\n",
    "                        dataFrames.append(pd.DataFrame([row],columns=columns))\n",
    "                        #concatenate a list of single dataframes after done with loop for speed \" pandas.concat\"\n",
    "                        #z score versus the standard deviation for single image, can normalize across all image\n",
    "\n",
    "                except ValueError as e:\n",
    "                    logger.exception(e)\n",
    "                    print(e)\n",
    "                    print(e, file=log)\n",
    "                    continue\n",
    "                 \n",
    "    \n",
    "# df = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\", names=columns)\n",
    "# for column in df.columns:\n",
    "#     if df[column].dtype == \"object\":\n",
    "#         df[column] = df[column].str.strip()\n",
    "# df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE_ML = []\n",
    "MSE_ML = []\n",
    "R2_ML = []\n",
    "R2_ML_train_test = []\n",
    "\n",
    "MAE_pCal = []\n",
    "MSE_pCal = []\n",
    "R2_pCal = []\n",
    "R2_pCal_train_test = []\n",
    "\n",
    "dfFixedTest_ML = []#df.iloc[[inds]]\n",
    "dfFixedTest_pCal = []#\n",
    "\n",
    "trainSamp = [100, 1000, 10000, 100000]\n",
    "for samp in trainSamp:\n",
    "    dataFrames = []\n",
    "    with open('logML', 'a') as log:\n",
    "\n",
    "        for (bb,dd,SS) in list(itertools.product([8],[207,208],[17])):\n",
    "            DD = str(dd).zfill(3)\n",
    "            lookup = f'M6C08_G{SS}_s2019{DD}'\n",
    "            ncFiles = [f for f in os.listdir(ncPath) if re.search(lookup,f)]\n",
    "            #ncFiles = mySort(ncFiles)\n",
    "            npFiles = [f for f in os.listdir( PATH ) if re.search(lookup,f)]\n",
    "            #ncFiles = mySort(ncFiles)\n",
    "            \n",
    "            randInds = nr.randint(samp, size=(x*y))\n",
    "            randInds.sort()\n",
    "\n",
    "            for ncf, npf in zip(ncFiles,npFiles):#for ncf, npf in zip(ncFiles,npFiles)[randInds] day sample <=576\n",
    "                try:\n",
    "                    imageBox = np.load(op.join( PATH,npf))\n",
    "                    myFile = xr.open_dataset(op.join(ncPath,ncf))\n",
    "                    planck_fk1 = float(myFile['planck_fk1'].data)\n",
    "                    planck_fk2 = float(myFile['planck_fk2'].data) \n",
    "                    planck_bc1 = float(myFile['planck_bc1'].data)                       \n",
    "                    planck_bc2 = float(myFile['planck_bc2'].data)\n",
    "\n",
    "                    time = ncf[31:38]\n",
    "                    G17_mean = Rad2BT(imageBox.mean(), planck_fk1, planck_fk2, planck_bc1, planck_bc2)\n",
    "                    G17_std = Rad2BT(imageBox.std(), planck_fk1, planck_fk2, planck_bc1, planck_bc2)\n",
    "\n",
    "                    hh = ncf[34:36]\n",
    "                    mm = ncf[36:38]\n",
    "\n",
    "                    print(ncf)\n",
    "                    print(str(ncf), file=log)\n",
    "                    logger.info(str(ncf))\n",
    "\n",
    "                    G16_npy = np.load( op.join(PATH, npf.replace('G16','G17',1)) )\n",
    "                    G16_ncf = xr.open_dataset(op.join( ncPath, ncf.replace('G16','G17',1) ))\n",
    "                    G16_fk1 = float(G16_ncf['planck_fk1'].data)\n",
    "                    G16_fk2 = float(G16_ncf['planck_fk2'].data) \n",
    "                    G16_bc1 = float(G16_ncf['planck_bc1'].data)                       \n",
    "                    G16_bc2 = float(G16_ncf['planck_bc2'].data)\n",
    "\n",
    "                    target_G16_Temp = Rad2BT(G16_npy, G16_fk1, G16_fk2, G16_bc1, G16_bc2)\n",
    "                    x,y = imageBox.shape[0],imageBox.shape[1]\n",
    "\n",
    "                    #select \"10,000\" random points out of 401,401\n",
    "                    sample = np.array([combo for combo in itertools.product(range(x),range(y))])\n",
    "                    for i,j in sample:\n",
    "                        lon = longitude( extent_pc[0], extent_pc[1], i, x )\n",
    "                        lat = latitude( extent_pc[2], extent_pc[3], j, y)\n",
    "\n",
    "                        G17_Temp = Rad2BT(imageBox[i,j], planck_fk1, planck_fk2, planck_bc1, planck_bc2)#unfiltered\n",
    "                        target_G16_Temp = Rad2BT( G16_npy[i,j], G16_fk1, G16_fk2, G16_bc1, G16_bc2 )\n",
    "\n",
    "                        row = [time, lon, lat, G17_Temp, G17_mean, G17_std, target_G16_Temp]\n",
    "\n",
    "                        dataFrames.append(pd.DataFrame([row],columns=columns))\n",
    "                        #concatenate a list of single dataframes after done with loop for speed \" pandas.concat\"\n",
    "                        #z score versus the standard deviation for single image, can normalize across all image\n",
    "\n",
    "                except ValueError as e:\n",
    "                    logger.exception(e)\n",
    "                    print(e)\n",
    "                    print(e, file=log)\n",
    "                    continue\n",
    "        df=pd.concat(dataFrames)\n",
    "        df = df.dropna()\n",
    "        \n",
    "        from sklearn.neural_network import MLPRegressor\n",
    "        #from sklearn.datasets import make_regression\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        from sklearn.metrics import mean_squared_error\n",
    "        \n",
    "        dfSample = df.sample(n=samp)\n",
    "        X = dfSample.drop([\"target_G16_Temp\"],axis=1).astype('float')#try as float\n",
    "        y = dfSample.drop(columns[:-1],axis=1).astype('float')\n",
    "            \n",
    "        from sklearn.metrics import mean_squared_error\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, np.ravel(y),random_state=1,test_size=0.0)\n",
    "        regr = MLPRegressor(random_state=1, max_iter=500).fit(X_train, y_train)\n",
    "        \n",
    "        \n",
    "        \n",
    "        If dd == 207:#non pCal\n",
    "            if len(dfFixedTest_ML)==0:\n",
    "                dfFixedTest_ML = df.sample(1000)\n",
    "                X_test = dfFixedTest_ML.drop([\"target_G16_Temp\"],axis=1).astype('float')\n",
    "                y_test = np.ravel(dfFixedTest_ML.drop(columns[:-1],axis=1).astype('float'))\n",
    "            \n",
    "            train = regr.score(X_train,y_train)\n",
    "            test = regr.score(X_test, y_test)\n",
    "            \n",
    "            R2_ML.append(train)\n",
    "            R2_ML_train_test.append(train/test)\n",
    "            \n",
    "            prediction = regr.predict(X_train)\n",
    "            errors = abs(prediction - y_train)\n",
    "            \n",
    "            MAE = round(np.mean(errors), 2)\n",
    "            MAE_ML.append(MAE)\n",
    "            \n",
    "            MSE = mean_squared_error(prediction, y_test)\n",
    "            MSE_ML.append(MSE)\n",
    "            \n",
    "        If dd == 208:#pCal        \n",
    "            if len(dfFixedTest_pCal)==0:\n",
    "                dfFixedTest_pCal = df.sample(1000)\n",
    "                X_test = dfFixedTest_pCal.drop([\"target_G16_Temp\"],axis=1).astype('float')\n",
    "                y_test = np.ravel(dfFixedTest_pCal.drop(columns[:-1],axis=1).astype('float'))\n",
    "            \n",
    "            train = regr.score(X_train,y_train)\n",
    "            test = regr.score(X_test, y_test)\n",
    "            \n",
    "            R2_pCal.append(train)\n",
    "            R2_pCal_train_test.append(train/test)\n",
    "            \n",
    "            prediction = regr.predict(X_train)\n",
    "            errors = abs(prediction - y_train)\n",
    "            \n",
    "            MAE = round(np.mean(errors), 2)\n",
    "            MAE_pCal.append(MAE)\n",
    "            \n",
    "            MSE = mean_squared_error(prediction, y_test)\n",
    "            MSE_pCal.append(MSE)\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-186-4137dbba7087>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataFrames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdfFixedTest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/adomakor412/conda/envs/MyEnv/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m     )\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/adomakor412/conda/envs/MyEnv/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No objects to concatenate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "df=pd.concat(dataFrames)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "#from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSample = df.sample(n=10000)\n",
    "X = dfSample.drop([\"target_G16_Temp\"],axis=1).astype('float')#try as float\n",
    "y = dfSample.drop(columns[:-1],axis=1).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>G17_Temp</th>\n",
       "      <th>G17_mean</th>\n",
       "      <th>G17_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1030000.0</td>\n",
       "      <td>1.069722</td>\n",
       "      <td>-12.583213</td>\n",
       "      <td>245.100156</td>\n",
       "      <td>243.715676</td>\n",
       "      <td>202.188943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1030000.0</td>\n",
       "      <td>0.272815</td>\n",
       "      <td>-13.118669</td>\n",
       "      <td>244.373029</td>\n",
       "      <td>243.715676</td>\n",
       "      <td>202.188943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1030000.0</td>\n",
       "      <td>0.021538</td>\n",
       "      <td>-0.401592</td>\n",
       "      <td>242.713931</td>\n",
       "      <td>243.715676</td>\n",
       "      <td>202.188943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1030000.0</td>\n",
       "      <td>1.371254</td>\n",
       "      <td>-12.672455</td>\n",
       "      <td>245.670513</td>\n",
       "      <td>243.715676</td>\n",
       "      <td>202.188943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1030000.0</td>\n",
       "      <td>1.155874</td>\n",
       "      <td>-9.682827</td>\n",
       "      <td>245.148061</td>\n",
       "      <td>243.715676</td>\n",
       "      <td>202.188943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        time  longitude   latitude    G17_Temp    G17_mean     G17_std\n",
       "0  1030000.0   1.069722 -12.583213  245.100156  243.715676  202.188943\n",
       "0  1030000.0   0.272815 -13.118669  244.373029  243.715676  202.188943\n",
       "0  1030000.0   0.021538  -0.401592  242.713931  243.715676  202.188943\n",
       "0  1030000.0   1.371254 -12.672455  245.670513  243.715676  202.188943\n",
       "0  1030000.0   1.155874  -9.682827  245.148061  243.715676  202.188943"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_G16_Temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>245.100156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>244.373029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>242.713931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>245.670513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>245.148061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target_G16_Temp\n",
       "0       245.100156\n",
       "0       244.373029\n",
       "0       242.713931\n",
       "0       245.670513\n",
       "0       245.148061"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, np.ravel(y),random_state=1,test_size=0.0)\n",
    "regr = MLPRegressor(random_state=1, max_iter=500).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dfFixedTest' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-185-ccd3f3bad7e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfFixedTest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"target_G16_Temp\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfFixedTest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dfFixedTest' is not defined"
     ]
    }
   ],
   "source": [
    "X_test = dfFixedTest.drop([\"target_G16_Temp\"],axis=1).astype('float')\n",
    "y_test = np.ravel(dfFixedTest.drop(columns[:-1],axis=1).astype('float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3371111954088859"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 1.02 Kelvin\n",
      "Mean Square Error: 1.5042751222963218\n"
     ]
    }
   ],
   "source": [
    "errors = abs(prediction - y_test)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'Kelvin')\n",
    "print('Mean Square Error:', mean_squared_error(prediction, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3332812812151569"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previous MSE was 23.96 at 1000 points sampled. Going from 1000 to 10000 points acheived better MSE (23.96 -> 0.36), MAE (3.02 Kelvins -> 0.52 Kelvins) and R^2 of both the test (-0.42 -> 0.61) and train (-0.32 ->0.6) data.\n",
    "\n",
    "### Since the R^2 of the train and test data are similar, we know we are not overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(8, 207, 16), (8, 207, 17), (8, 208, 16), (8, 208, 17)]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(itertools.product([8],[207,208],[16,17]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
