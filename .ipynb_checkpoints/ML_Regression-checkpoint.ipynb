{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/adomakor412/conda/envs/MyEnv/lib/python3.6/site-packages/dask/config.py:131: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from os import path as op\n",
    "import itertools\n",
    "import re\n",
    "import xarray as xr\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy.random as nr\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr.seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputPath = '/scratch/adomakor412/all_npy3'\n",
    "PATH = os.path.expanduser(inputPath)\n",
    "ncPath = os.path.expanduser('/scratch/adomakor412/april_data_2019')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"time\",\n",
    "    \"longitude\",\n",
    "    \"latitude\",\n",
    "    #\"band\",#Necessary?\n",
    "    \"G17_Temp\",\n",
    "    \"G17_mean\",\n",
    "    \"G17_std\",#mean and std outside inner for loop for comp. eff.\n",
    "    \"target_G16_Temp\"\n",
    "]\n",
    "\n",
    "df = pd.DataFrame({},columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longitude(lonMin, lonMax, col, colSize):\n",
    "    lon = (col/colSize)* (lonMax - lonMin)\n",
    "    return lon\n",
    "\n",
    "def latitude(latMin, latMax, row, rowSize):\n",
    "    lat = (row/rowSize)* (latMax - latMin)\n",
    "    return lat\n",
    "\n",
    "def Rad2BT(rad, planck_fk1, planck_fk2, planck_bc1, planck_bc2):\n",
    "    \"\"\"Radiances to Brightness Temprature (using black body equation)\"\"\"\n",
    "    invRad = np.array(rad)**(-1)\n",
    "    arg = (invRad*planck_fk1) + 1.0\n",
    "    T = (- planck_bc1+(planck_fk2 * (np.log(arg)**(-1))) )*(1/planck_bc2) \n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OR_ABI-L1b-RadF-M6C08_G17_s20191030000339_e20191030009405_c20191030009441.nc\n"
     ]
    }
   ],
   "source": [
    "extent_pc = [-109.59326, -102.40674, 8.94659, -8.94656]\n",
    "\n",
    "with open('logML', 'a') as log:   \n",
    "    for (bb,dd) in list(itertools.product([8],[5])):#Let's start with one day\n",
    "        DD = str(98+dd).zfill(3)\n",
    "        lookup = f'M6C08_G17_s2019{DD}0000'\n",
    "        ncFiles = [f for f in os.listdir(ncPath) if re.search(lookup,f)]\n",
    "        #ncFiles = mySort(ncFiles)\n",
    "        npFiles = [f for f in os.listdir( PATH ) if re.search(lookup,f)]\n",
    "        #ncFiles = mySort(ncFiles)\n",
    "\n",
    "        for ncf, npf in zip(ncFiles,npFiles):\n",
    "            try:\n",
    "                imageBox = np.load(op.join( PATH,npf))\n",
    "                myFile = xr.open_dataset(op.join(ncPath,ncf))\n",
    "                planck_fk1 = float(myFile['planck_fk1'].data)\n",
    "                planck_fk2 = float(myFile['planck_fk2'].data) \n",
    "                planck_bc1 = float(myFile['planck_bc1'].data)                       \n",
    "                planck_bc2 = float(myFile['planck_bc2'].data)\n",
    "\n",
    "                time = ncf[31:38]\n",
    "                G17_mean = Rad2BT(imageBox.mean(), planck_fk1, planck_fk2, planck_bc1, planck_bc2)\n",
    "                G17_std = Rad2BT(imageBox.std(), planck_fk1, planck_fk2, planck_bc1, planck_bc2)\n",
    "\n",
    "                hh = ncf[34:36]\n",
    "                mm = ncf[36:38]\n",
    "                \n",
    "                print(ncf)\n",
    "                print(str(ncf), file=log)\n",
    "                logger.info(str(ncf))\n",
    "\n",
    "                G16_npy = np.load( op.join(PATH, npf.replace('G16','G17',1)) )\n",
    "                G16_ncf = xr.open_dataset(op.join( ncPath, ncf.replace('G16','G17',1) ))\n",
    "                G16_fk1 = float(G16_ncf['planck_fk1'].data)\n",
    "                G16_fk2 = float(G16_ncf['planck_fk2'].data) \n",
    "                G16_bc1 = float(G16_ncf['planck_bc1'].data)                       \n",
    "                G16_bc2 = float(G16_ncf['planck_bc2'].data)\n",
    "\n",
    "                target_G16_Temp = Rad2BT(G16_npy, G16_fk1, G16_fk2, G16_bc1, G16_bc2)\n",
    "                x,y = imageBox.shape[0],imageBox.shape[1]\n",
    "                for i,j in itertools.product(range(x),range(y)):\n",
    "                    lon = longitude( extent_pc[0], extent_pc[1], i, x )\n",
    "                    lat = latitude( extent_pc[2], extent_pc[3], j, y)\n",
    "\n",
    "                    G17_Temp = Rad2BT(imageBox[i,j], planck_fk1, planck_fk2, planck_bc1, planck_bc2)#unfiltered\n",
    "                    target_G16_Temp = Rad2BT( G16_npy[i,j], G16_fk1, G16_fk2, G16_bc1, G16_bc2 )\n",
    "                    \n",
    "                    row = [time, lon, lat, G17_Temp, G17_mean, G17_std, target_G16_Temp]\n",
    "\n",
    "                    df = df.append(pd.DataFrame([row],columns=columns),ignore_index=True)\n",
    "                    \n",
    "            except ValueError as e:\n",
    "                logger.exception(e)\n",
    "                print(e)\n",
    "                print(e, file=log)\n",
    "                continue \n",
    "    \n",
    "# df = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\", names=columns)\n",
    "# for column in df.columns:\n",
    "#     if df[column].dtype == \"object\":\n",
    "#         df[column] = df[column].str.strip()\n",
    "# df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
