{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/adomakor412/conda/envs/MyEnv/lib/python3.6/site-packages/dask/config.py:131: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from os import path as op\n",
    "import itertools\n",
    "import re\n",
    "import xarray as xr\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy.random as nr\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr.seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputPath = '/scratch/adomakor412/july_25-26_2019_npy'\n",
    "PATH = os.path.expanduser(inputPath)\n",
    "ncPath = os.path.expanduser('/scratch/adomakor412/july_25-26_2019')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"time\",\n",
    "    \"longitude\",\n",
    "    \"latitude\",\n",
    "    #\"band\",#Necessary?\n",
    "    \"G17_Temp\",\n",
    "    \"G17_mean\",\n",
    "    \"G17_std\",#mean and std outside inner for loop for comp. eff.\n",
    "    \"target_G16_Temp\"\n",
    "]\n",
    "\n",
    "df = pd.DataFrame({},columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longitude(lonMin, lonMax, col, colSize):\n",
    "    lon = (col/colSize)* (lonMax - lonMin)\n",
    "    return lon\n",
    "\n",
    "def latitude(latMin, latMax, row, rowSize):\n",
    "    lat = (row/rowSize)* (latMax - latMin)\n",
    "    return lat\n",
    "\n",
    "def Rad2BT(rad, planck_fk1, planck_fk2, planck_bc1, planck_bc2):\n",
    "    \"\"\"Radiances to Brightness Temprature (using black body equation)\"\"\"\n",
    "    invRad = np.array(rad)**(-1)\n",
    "    arg = (invRad*planck_fk1) + 1.0\n",
    "    T = (- planck_bc1+(planck_fk2 * (np.log(arg)**(-1))) )*(1/planck_bc2) \n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "extent_pc = [-109.59326, -102.40674, 8.94659, -8.94656]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a fixed test set of size 10^5 of random pixels to be compared to training sets. We create a fixed test set for both MLP and pCal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping up on sample\n",
      "Working on MLP sample\n",
      "Wrapping up on sample\n",
      "Working on pCal sample\n"
     ]
    }
   ],
   "source": [
    "dfFixed_ML = []#df.iloc[[inds]]\n",
    "dfFixed_pCal = []\n",
    "\n",
    "trainSamp = [100000]\n",
    "\n",
    "for samp in trainSamp:\n",
    "    dataFrames = []\n",
    "    with open('logML', 'a') as log:\n",
    "        for (bb,dd,SS) in list(itertools.product([8],[206,207],[17])):\n",
    "            DD = str(dd).zfill(3)\n",
    "            lookup = f'M6C08_G{SS}_s2019{DD}1200'\n",
    "            ncFiles = [f for f in os.listdir(ncPath) if re.search(lookup,f)]\n",
    "            #ncFiles = mySort(ncFiles)\n",
    "            npFiles = [f for f in os.listdir( PATH ) if re.search(lookup,f)] #Numpy files not fully data cleaned\n",
    "            #ncFiles = mySort(ncFiles)\n",
    "            \n",
    "            #randInds = nr.randint(samp, size=(x*y))\n",
    "            #randInds.sort()\n",
    "\n",
    "            for ncf, npf in zip(ncFiles,npFiles):#for ncf, npf in zip(ncFiles,npFiles)[randInds] day sample <=576\n",
    "                try:\n",
    "                    imageBox = np.load(op.join( PATH,npf))\n",
    "                    myFile = xr.open_dataset(op.join(ncPath,ncf))\n",
    "                    planck_fk1 = float(myFile['planck_fk1'].data)\n",
    "                    planck_fk2 = float(myFile['planck_fk2'].data) \n",
    "                    planck_bc1 = float(myFile['planck_bc1'].data)                       \n",
    "                    planck_bc2 = float(myFile['planck_bc2'].data)\n",
    "\n",
    "                    time = ncf[31:38]\n",
    "                    G17_mean = Rad2BT(imageBox.mean(), planck_fk1, planck_fk2, planck_bc1, planck_bc2)\n",
    "                    G17_std = Rad2BT(imageBox.std(), planck_fk1, planck_fk2, planck_bc1, planck_bc2)\n",
    "\n",
    "                    hh = ncf[34:36]\n",
    "                    mm = ncf[36:38]\n",
    "\n",
    "                    print(str(ncf), file=log)\n",
    "                    logger.info(str(ncf))\n",
    "\n",
    "                    G16_npy = np.load( op.join(PATH, npf.replace('G16','G17',1)) )\n",
    "                    G16_ncf = xr.open_dataset(op.join( ncPath, ncf.replace('G16','G17',1) ))\n",
    "                    G16_fk1 = float(G16_ncf['planck_fk1'].data)\n",
    "                    G16_fk2 = float(G16_ncf['planck_fk2'].data) \n",
    "                    G16_bc1 = float(G16_ncf['planck_bc1'].data)                       \n",
    "                    G16_bc2 = float(G16_ncf['planck_bc2'].data)\n",
    "\n",
    "                    target_G16_Temp = Rad2BT(G16_npy, G16_fk1, G16_fk2, G16_bc1, G16_bc2)\n",
    "                    x,y = imageBox.shape[0],imageBox.shape[1]\n",
    "\n",
    "                    #select \"10,000\" random points out of 401,401\n",
    "                    sample = np.array([combo for combo in itertools.product(range(x),range(y))])\n",
    "                    inds=nr.randint(x*y, size=(samp))\n",
    "                    inds.sort()\n",
    "                    \n",
    "                    for i,j in sample[inds]:#bottleneck for time\n",
    "                        lon = longitude( extent_pc[0], extent_pc[1], i, x )\n",
    "                        lat = latitude( extent_pc[2], extent_pc[3], j, y)\n",
    "\n",
    "                        G17_Temp = Rad2BT(imageBox[i,j], planck_fk1, planck_fk2, planck_bc1, planck_bc2)#nonfilter\n",
    "                        target_G16_Temp = Rad2BT( G16_npy[i,j], G16_fk1, G16_fk2, G16_bc1, G16_bc2 )\n",
    "\n",
    "                        row = [time, lon, lat, G17_Temp, G17_mean, G17_std, target_G16_Temp]\n",
    "\n",
    "                        dataFrames.append(pd.DataFrame([row],columns=columns))\n",
    "                        #concatenate a list of single dataframes after done with loop for speed \" pandas.concat\"\n",
    "                        #z score versus the standard deviation for single image, can normalize across all image\n",
    "                 \n",
    "                    print('Wrapping up on sample')\n",
    "\n",
    "                    df=pd.concat(dataFrames)\n",
    "                    df = df.dropna()\n",
    "                    df = df[ df[\"G17_Temp\"] > 0]\n",
    "                    df = df[ df[\"target_G16_Temp\"] > 0]\n",
    "\n",
    "                    dfSample = df#df.sample(n=samp)\n",
    "\n",
    "                    if int(DD) == 206:#non pCal\n",
    "                        print('Working on MLP sample')\n",
    "                        dfFixed_ML = dfSample\n",
    "\n",
    "                    if int(DD) == 207:#pCal        \n",
    "                        print('Working on pCal sample')\n",
    "                        dfFixed_pCal = dfSample\n",
    "                        \n",
    "                except ValueError as e:\n",
    "                    logger.exception(e)\n",
    "                    print(e)\n",
    "                    print(e, file=log)\n",
    "                    continue\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, we generate the training sets of various sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on samples of size: 100\n",
      "Working on MLP sample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/adomakor412/conda/envs/MyEnv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 74.5 GiB for an array with shape (100000, 100000) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-261890c717b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mX_testScaled\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                         \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mY_testScaled\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                         \u001b[0mMAE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 74.5 GiB for an array with shape (100000, 100000) and data type float64"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "inputPath = '/scratch/adomakor412/july_25-26_2019_npy'\n",
    "PATH = os.path.expanduser(inputPath)\n",
    "ncPath = os.path.expanduser('/scratch/adomakor412/july_25-26_2019')\n",
    "\n",
    "MAE_ML = []\n",
    "MSE_ML = []\n",
    "R2_ML = []\n",
    "R2_ML_train_test = []\n",
    "\n",
    "MAE_pCal = []\n",
    "MSE_pCal = []\n",
    "R2_pCal = []\n",
    "R2_pCal_train_test = []\n",
    "\n",
    "dfTarget_ML = []#df.iloc[[inds]]\n",
    "dfTarget_pCal = []\n",
    "dfPredict_ML = []\n",
    "dfPredict_pCal = []\n",
    "\n",
    "trainSamp = [100, 1000, 10000, 100000]\n",
    "\n",
    "for samp in trainSamp:\n",
    "    dataFrames = []\n",
    "    with open('logML', 'a') as log:\n",
    "        for (bb,dd,SS) in list(itertools.product([8],[206,207],[17])):\n",
    "            DD = str(dd).zfill(3)\n",
    "            lookup = f'M6C08_G{SS}_s2019{DD}1200'\n",
    "            ncFiles = [f for f in os.listdir(ncPath) if re.search(lookup,f)]\n",
    "            #ncFiles = mySort(ncFiles)\n",
    "            npFiles = [f for f in os.listdir( PATH ) if re.search(lookup,f)]\n",
    "            #ncFiles = mySort(ncFiles)\n",
    "            \n",
    "            #randInds = nr.randint(samp, size=(x*y))\n",
    "            #randInds.sort()\n",
    "\n",
    "            for ncf, npf in zip(ncFiles,npFiles):#for ncf, npf in zip(ncFiles,npFiles)[randInds] day sample <=576\n",
    "                try:\n",
    "                    imageBox = np.load(op.join( PATH,npf))\n",
    "                    myFile = xr.open_dataset(op.join(ncPath,ncf))\n",
    "                    planck_fk1 = float(myFile['planck_fk1'].data)\n",
    "                    planck_fk2 = float(myFile['planck_fk2'].data) \n",
    "                    planck_bc1 = float(myFile['planck_bc1'].data)                       \n",
    "                    planck_bc2 = float(myFile['planck_bc2'].data)\n",
    "\n",
    "                    time = ncf[31:38]\n",
    "                    G17_mean = Rad2BT(imageBox.mean(), planck_fk1, planck_fk2, planck_bc1, planck_bc2)\n",
    "                    G17_std = Rad2BT(imageBox.std(), planck_fk1, planck_fk2, planck_bc1, planck_bc2)\n",
    "\n",
    "                    hh = ncf[34:36]\n",
    "                    mm = ncf[36:38]\n",
    "\n",
    "                    print(str(ncf), file=log)\n",
    "                    logger.info(str(ncf))\n",
    "\n",
    "                    G16_npy = np.load( op.join(PATH, npf.replace('G16','G17',1)) )\n",
    "                    G16_ncf = xr.open_dataset(op.join( ncPath, ncf.replace('G16','G17',1) ))\n",
    "                    G16_fk1 = float(G16_ncf['planck_fk1'].data)\n",
    "                    G16_fk2 = float(G16_ncf['planck_fk2'].data) \n",
    "                    G16_bc1 = float(G16_ncf['planck_bc1'].data)                       \n",
    "                    G16_bc2 = float(G16_ncf['planck_bc2'].data)\n",
    "\n",
    "                    target_G16_Temp = Rad2BT(G16_npy, G16_fk1, G16_fk2, G16_bc1, G16_bc2)\n",
    "                    x,y = imageBox.shape[0],imageBox.shape[1]\n",
    "\n",
    "                    #select \"10,000\" random points out of 401,401\n",
    "                    sample = np.array([combo for combo in itertools.product(range(x),range(y))])\n",
    "                    inds=nr.randint(x*y, size=(samp))\n",
    "                    inds.sort()\n",
    "                    \n",
    "                    for i,j in sample[inds]:#bottleneck for time\n",
    "                        lon = longitude( extent_pc[0], extent_pc[1], i, x )\n",
    "                        lat = latitude( extent_pc[2], extent_pc[3], j, y)\n",
    "\n",
    "                        G17_Temp = Rad2BT(imageBox[i,j], planck_fk1, planck_fk2, planck_bc1, planck_bc2)#nonfilter\n",
    "                        target_G16_Temp = Rad2BT( G16_npy[i,j], G16_fk1, G16_fk2, G16_bc1, G16_bc2 )\n",
    "\n",
    "                        row = [time, lon, lat, G17_Temp, G17_mean, G17_std, target_G16_Temp]\n",
    "\n",
    "                        dataFrames.append(pd.DataFrame([row],columns=columns))\n",
    "                        #concatenate a list of single dataframes after done with loop for speed \" pandas.concat\"\n",
    "                        #z score versus the standard deviation for single image, can normalize across all image\n",
    "                    \n",
    "                    df=pd.concat(dataFrames)\n",
    "                    df = df.dropna()\n",
    "                    df = df[ df[\"G17_Temp\"] > 0]\n",
    "                    df = df[ df[\"target_G16_Temp\"] > 0]\n",
    "\n",
    "                    from sklearn.neural_network import MLPRegressor\n",
    "                    #from sklearn.datasets import make_regression\n",
    "                    from sklearn.model_selection import train_test_split\n",
    "                    from sklearn.metrics import mean_squared_error\n",
    "\n",
    "                    dfSample = df.sample(n=samp)\n",
    "                    X = dfSample.drop([\"target_G16_Temp\"],axis=1).astype('float')#try as float\n",
    "                    y = dfSample.drop(columns[:-1],axis=1).astype('float')\n",
    "\n",
    "                    from sklearn.metrics import mean_squared_error\n",
    "                    '''Scaled data frame retaining columns whose values vary'''\n",
    "                    '''Scaling is done on columns'''\n",
    "                    #print(scaler.scale_)\n",
    "                    #print(scaler.var_)\n",
    "                    #print(scaler.mean_)\n",
    "                    \n",
    "                    X_train, X_test, y_train, y_test = train_test_split(X, np.ravel(y),random_state=1,test_size=0)\n",
    "                    #We have enough data so we don't necessarily need to leave a percentage aside for testing\n",
    "                    \n",
    "                    scalerTrainX = StandardScaler()\n",
    "                    scalerTrainY = StandardScaler()                  \n",
    "                    \n",
    "                    #testing for one file, drop constant columns for stability in scaling\n",
    "                    X_trainScaled = pd.DataFrame(X_train,columns = columns[:-1])\n",
    "                    X_trainScaled = X_trainScaled.drop(['time','G17_mean','G17_std'],axis=1)#.astype('float')\n",
    "                    \n",
    "                    Y_trainScaled = pd.DataFrame(y_train,columns = [columns[-1]])#.astype('float')\n",
    "                    \n",
    "                    scalerTrainX.fit(X_trainScaled)\n",
    "                    scalerTrainY.fit(Y_trainScaled)\n",
    "                    \n",
    "                    '''MSE and MAE are more interpretable with scaling of Target Variable.'''\n",
    "                    regr = MLPRegressor(random_state=1, max_iter=500).fit(X_trainScaled, Y_trainScaled)               \n",
    "                    \n",
    "                    print('Working on samples of size:', samp)\n",
    "                    if int(DD) == 206:#non pCal\n",
    "                        print('Working on MLP sample')\n",
    "                        \n",
    "                        X_test = dfFixed_ML.drop([\"target_G16_Temp\"],axis=1)#.astype('float')\n",
    "                        y_test = dfFixed_ML.drop(columns[:-1],axis=1)#.astype('float')\n",
    "                        \n",
    "                        X_test =X_test.drop(['time','G17_mean','G17_std'],axis=1)\n",
    "                        \n",
    "                        X_testScaled = scalerTrainX.transform(X_test)\n",
    "                        Y_testScaled = scalerTrainY.transform(y_test)\n",
    "\n",
    "                        prediction = regr.predict( X_testScaled )\n",
    "                        errors = abs( prediction - Y_testScaled )\n",
    "\n",
    "                        MAE = round(np.mean(errors), 2)\n",
    "                        MAE_ML.append(MAE)\n",
    "\n",
    "                        MSE = mean_squared_error(prediction, Y_testScaled)\n",
    "                        MSE_ML.append(MSE)\n",
    "\n",
    "                        print(MAE_ML,file=log) \n",
    "                        print(MSE_ML,file=log)\n",
    "                        \n",
    "                        dfTarget_ML.append(Y_testScaled)\n",
    "                        dfPredict_ML.append(prediction)\n",
    "\n",
    "                    if int(DD) == 207:#pCal        \n",
    "                        print('Working on pCal sample')\n",
    "                        \n",
    "                        X_test = dfFixed_pCal.drop([\"target_G16_Temp\"],axis=1)#.astype('float')\n",
    "                        y_test = dfFixed_pCal.drop(columns[:-1],axis=1)#.astype('float')\n",
    "                        \n",
    "                        X_test =X_test.drop(['time','G17_mean','G17_std'],axis=1)\n",
    "                        \n",
    "                        X_testScaled = scalerTrainX.transform(X_test)\n",
    "                        Y_testScaled = scalerTrainY.transform(y_test)\n",
    "\n",
    "                        prediction = regr.predict( X_testScaled )\n",
    "                        errors = abs( prediction - Y_testScaled )\n",
    "\n",
    "                        MAE = round(np.mean(errors), 2)\n",
    "                        MAE_pCal.append(MAE)\n",
    "\n",
    "                        MSE = mean_squared_error(prediction, Y_testScaled)\n",
    "                        MSE_pCal.append(MSE)\n",
    "\n",
    "                        print(MAE_pCal,file=log) \n",
    "                        print(MSE_pCal,file=log)\n",
    "                        \n",
    "                        dfTarget_pCal.append(Y_testScaled)\n",
    "                        dfPredict_pCal.append(prediction)\n",
    "                        \n",
    "                except ValueError as e:\n",
    "                    logger.exception(e)\n",
    "                    print(e)\n",
    "                    print(e, file=log)\n",
    "                    continue\n",
    "                    \n",
    "                \n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000,)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points =['1000','10000','100000']\n",
    "\n",
    "pairs_ML = (dfTarget_ML[1:],dfPredict_ML[1:])\n",
    "pairs_pCal = (dfTarget_pCal[1:], dfPredict_pCal[1:])\n",
    "pairs = (pairs_ML,pairs_pCal)\n",
    "\n",
    "\n",
    "name = ['MLP','pCal']\n",
    "#for i, (ML, pCal) in enumerate(pairs):\n",
    "for color in points:\n",
    "    i = points.index(color)\n",
    "    for j, label in enumerate(name):\n",
    "        plt.scatter(pairs[j][0][i], pairs[j][1][i], alpha=0.1, label=label)\n",
    "    plt.title(f'Scatter plot on fit for {color} sample points')\n",
    "    plt.xlabel(\"Target Values\")\n",
    "    plt.ylabel(\"Prediction\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (3,) and (0,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-56183be9105e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mML\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpCal\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"center right\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/adomakor412/conda/envs/MyEnv/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2787\u001b[0m     return gca().plot(\n\u001b[1;32m   2788\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2789\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2791\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/adomakor412/conda/envs/MyEnv/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1664\u001b[0m         \"\"\"\n\u001b[1;32m   1665\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1666\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1667\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/adomakor412/conda/envs/MyEnv/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/adomakor412/conda/envs/MyEnv/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/adomakor412/conda/envs/MyEnv/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 270\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (3,) and (0,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#points =['100','1000','10000','100000']\n",
    "points =['1000','10000','100000']#Interpretable scale for minimum training points\n",
    "# metric_pCal = [MAE_pCal, MSE_pCal]\n",
    "# metric_ML = [MAE_ML, MSE_ML]\n",
    "metric_pCal = [MAE_pCal[1:], MSE_pCal[1:]]\n",
    "metric_ML = [MAE_ML[1:], MSE_ML[1:]]\n",
    "# metric_pCal = [MAE_pCal, MSE_pCal, R2_pCal, R2_pCal_train_test]\n",
    "# metric_ML = [MAE_ML, MSE_ML, R2_ML, R2_ML_train_test]\n",
    "metric = [metric_ML, metric_pCal]\n",
    "name = ['MLP','pCal']\n",
    "ylabels = ['Kelvin','Kelvin^2','R-square','R^2_train/ R^2_test']\n",
    "titles = ['Mean Absolute Error MLP vs pCal',\n",
    "          'Mean Square Error MLP vs pCal',\n",
    "          'R-Square MLP vs pCal',\n",
    "          'R-Square ratios of MLP vs pCal']\n",
    "\n",
    "pairs = list(zip(metric_ML,metric_pCal))\n",
    "for i, (ML, pCal) in enumerate(pairs):   \n",
    "    for j, label in enumerate(name):\n",
    "        plt.plot(points, pairs[i][j], label=label)\n",
    "    plt.title(titles[i])\n",
    "    plt.legend(loc=\"center right\")\n",
    "    plt.xlabel(\"sample size\")\n",
    "    plt.ylabel(ylabels[i])\n",
    "    \n",
    "    \n",
    "    plt.show()   \n",
    "#for i in range(len(points)):    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-5ba078894313>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'MAE'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'MSE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmetric_pCal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric_pCal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mmetric_ML\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric_ML\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#metric = ['MAE','MSE','R-Square','Validation ratio']\n",
    "metric = ['MAE','MSE']\n",
    "for i,j in itertools.product(range(len(metric)), range(len(metric))):\n",
    "    metric_pCal[i][j] = round(metric_pCal[i][j],2)\n",
    "    metric_ML[i][j] = round(metric_ML[i][j],2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metric_ML)\n",
    "print(metric_pCal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "for i in range(len(trainSamp)):\n",
    "    fig = go.Figure(data=[go.Table(header=dict(values=[f'Metric {points[i]}pts','MLP', 'pCal']),\n",
    "                     cells=dict(values=[metric, np.array(metric_ML).T[i],  np.array(metric_pCal).T[i]]))\n",
    "                         ])\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
